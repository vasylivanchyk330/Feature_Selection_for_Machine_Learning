{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicated features\n",
    "\n",
    "Often datasets contain duplicated features, that is, features that despite having different names, are identical.\n",
    "\n",
    "They are not ok for **one hot encoding**.\n",
    "\n",
    "There is no function in Pandas to find duplicated columns, so there is a need to write a code to do so.\n",
    "\n",
    "The method below works for both **numerical and categorical** variables.\n",
    "\n",
    "(In this demo, I will demonstrate how to deal withduplicated features using a toy dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 301)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "data = pd.read_csv('../dataset_1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note**: do feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1), # drop the target\n",
    "    data['target'], # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant and quasi-constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant values\n",
    "    predominant = (X_train[feature].value_counts() / np.float(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate predominant feature\n",
    "    if predominant > 0.998:\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 158), (15000, 158))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop these columns from the train and test sets:\n",
    "\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an empty dictionary to store the groups of duplicates\n",
    "duplicated_feat_pairs = {}\n",
    "\n",
    "# create an empty list to collect duplicated features\n",
    "_duplicated_feat = []\n",
    "\n",
    "for i in range(0, len(X_train.columns)):\n",
    "\n",
    "    feat_1 = X_train.columns[i]\n",
    "\n",
    "    if feat_1 not in _duplicated_feat:\n",
    "    \n",
    "        # create an empty list as an entry for this feature in the dictionary\n",
    "        duplicated_feat_pairs[feat_1] = []\n",
    "\n",
    "        # iterate over the remaining features of the dataset\n",
    "        for feat_2 in X_train.columns[i + 1:]:\n",
    "\n",
    "            # check if this second feature is identical to the first one\n",
    "            if X_train[feat_1].equals(X_train[feat_2]):\n",
    "\n",
    "                # if yes, append it to the list in the dictionary\n",
    "                duplicated_feat_pairs[feat_1].append(feat_2)\n",
    "                \n",
    "                # and append it to the list with duplicated variable names only\n",
    "                _duplicated_feat.append(feat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['var_148', 'var_199', 'var_296', 'var_250', 'var_232', 'var_269']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(_duplicated_feat)\n",
    "print(len(_duplicated_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found 6 features that were duplicates of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_4': [],\n",
       " 'var_5': [],\n",
       " 'var_8': [],\n",
       " 'var_13': [],\n",
       " 'var_15': [],\n",
       " 'var_17': [],\n",
       " 'var_18': [],\n",
       " 'var_19': [],\n",
       " 'var_21': [],\n",
       " 'var_22': [],\n",
       " 'var_25': [],\n",
       " 'var_26': [],\n",
       " 'var_27': [],\n",
       " 'var_29': [],\n",
       " 'var_30': [],\n",
       " 'var_31': [],\n",
       " 'var_35': [],\n",
       " 'var_37': ['var_148'],\n",
       " 'var_38': [],\n",
       " 'var_41': [],\n",
       " 'var_46': [],\n",
       " 'var_47': [],\n",
       " 'var_49': [],\n",
       " 'var_50': [],\n",
       " 'var_51': [],\n",
       " 'var_52': [],\n",
       " 'var_54': [],\n",
       " 'var_55': [],\n",
       " 'var_57': [],\n",
       " 'var_58': [],\n",
       " 'var_62': [],\n",
       " 'var_63': [],\n",
       " 'var_64': [],\n",
       " 'var_68': [],\n",
       " 'var_70': [],\n",
       " 'var_74': [],\n",
       " 'var_75': [],\n",
       " 'var_76': [],\n",
       " 'var_79': [],\n",
       " 'var_82': [],\n",
       " 'var_83': [],\n",
       " 'var_84': ['var_199'],\n",
       " 'var_85': [],\n",
       " 'var_86': [],\n",
       " 'var_88': [],\n",
       " 'var_91': [],\n",
       " 'var_93': [],\n",
       " 'var_94': [],\n",
       " 'var_96': [],\n",
       " 'var_100': [],\n",
       " 'var_101': [],\n",
       " 'var_103': [],\n",
       " 'var_105': [],\n",
       " 'var_107': [],\n",
       " 'var_108': [],\n",
       " 'var_109': [],\n",
       " 'var_110': [],\n",
       " 'var_114': [],\n",
       " 'var_117': [],\n",
       " 'var_118': [],\n",
       " 'var_119': [],\n",
       " 'var_121': [],\n",
       " 'var_123': [],\n",
       " 'var_128': [],\n",
       " 'var_131': [],\n",
       " 'var_132': [],\n",
       " 'var_134': [],\n",
       " 'var_137': [],\n",
       " 'var_139': [],\n",
       " 'var_140': [],\n",
       " 'var_143': ['var_296'],\n",
       " 'var_144': [],\n",
       " 'var_145': [],\n",
       " 'var_147': [],\n",
       " 'var_152': [],\n",
       " 'var_154': [],\n",
       " 'var_155': [],\n",
       " 'var_156': [],\n",
       " 'var_157': [],\n",
       " 'var_160': [],\n",
       " 'var_161': [],\n",
       " 'var_162': [],\n",
       " 'var_163': [],\n",
       " 'var_164': [],\n",
       " 'var_165': [],\n",
       " 'var_166': [],\n",
       " 'var_168': [],\n",
       " 'var_169': [],\n",
       " 'var_172': [],\n",
       " 'var_173': [],\n",
       " 'var_174': [],\n",
       " 'var_175': [],\n",
       " 'var_176': [],\n",
       " 'var_177': ['var_250'],\n",
       " 'var_179': [],\n",
       " 'var_181': [],\n",
       " 'var_185': [],\n",
       " 'var_186': [],\n",
       " 'var_188': [],\n",
       " 'var_190': [],\n",
       " 'var_191': [],\n",
       " 'var_192': [],\n",
       " 'var_193': [],\n",
       " 'var_194': [],\n",
       " 'var_198': [],\n",
       " 'var_200': [],\n",
       " 'var_203': [],\n",
       " 'var_205': [],\n",
       " 'var_206': [],\n",
       " 'var_207': [],\n",
       " 'var_208': [],\n",
       " 'var_209': [],\n",
       " 'var_213': [],\n",
       " 'var_214': [],\n",
       " 'var_218': [],\n",
       " 'var_220': [],\n",
       " 'var_222': [],\n",
       " 'var_226': ['var_232'],\n",
       " 'var_229': ['var_269'],\n",
       " 'var_230': [],\n",
       " 'var_231': [],\n",
       " 'var_238': [],\n",
       " 'var_240': [],\n",
       " 'var_241': [],\n",
       " 'var_242': [],\n",
       " 'var_244': [],\n",
       " 'var_252': [],\n",
       " 'var_253': [],\n",
       " 'var_255': [],\n",
       " 'var_256': [],\n",
       " 'var_258': [],\n",
       " 'var_259': [],\n",
       " 'var_261': [],\n",
       " 'var_262': [],\n",
       " 'var_266': [],\n",
       " 'var_268': [],\n",
       " 'var_270': [],\n",
       " 'var_271': [],\n",
       " 'var_272': [],\n",
       " 'var_273': [],\n",
       " 'var_275': [],\n",
       " 'var_276': [],\n",
       " 'var_277': [],\n",
       " 'var_278': [],\n",
       " 'var_279': [],\n",
       " 'var_281': [],\n",
       " 'var_284': [],\n",
       " 'var_288': [],\n",
       " 'var_292': [],\n",
       " 'var_293': [],\n",
       " 'var_295': [],\n",
       " 'var_300': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_feat_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for every feature, if it had duplicates, we have entries in the list, otherwise, we have empty lists. Let's explore those features with duplicates now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "# let's explore the number of keys in our dictionary\n",
    "\n",
    "# we see it is 152, because 6 of the 158 were duplicates,\n",
    "# so they were not included as keys\n",
    "\n",
    "print(len(duplicated_feat_pairs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_37 ['var_148']\n",
      "\n",
      "var_84 ['var_199']\n",
      "\n",
      "var_143 ['var_296']\n",
      "\n",
      "var_177 ['var_250']\n",
      "\n",
      "var_226 ['var_232']\n",
      "\n",
      "var_229 ['var_269']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the features with its duplicates\n",
    "\n",
    "for feat in duplicated_feat_pairs.keys():\n",
    "    \n",
    "    if len(duplicated_feat_pairs[feat]) > 0:\n",
    "\n",
    "        # print the feature and its duplicates:\n",
    "        print(feat, duplicated_feat_pairs[feat])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 152), (15000, 152))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, remove the duplicates by retaining\n",
    "# the keys of the dictionary\n",
    "\n",
    "X_train = X_train[duplicated_feat_pairs.keys()]\n",
    "X_test = X_test[duplicated_feat_pairs.keys()]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
